nameOverride: ""
fullnameOverride: ""
log_level: INFO
connect:
  replicaCount: 1
  imagePullSecrets: [ ]

  image:
    repository: quay.io/debezium/connect
    pullPolicy: IfNotPresent
    tag: "2.7"

  service:
    type: ClusterIP
    port: 8083
    protocol: TCP
    name: http

  ingress:
    enabled: false

  autoscaling:
    enabled: false

  resources:
    limits:
      cpu: 1000m
      memory: 2Gi
    requests:
      cpu: 500m
      memory: 1Gi

  properties:
    group_id: "debezium-odse-srte-connector-v013125"
    topics_basename: "debezium-odse-srte-connector"
    default_replication_factor: 2
    default_partitions: 10
    default_cleanup: "compact"
    sql_server_agent_override: false
    sql_server_agent_status: ""
    bootstrap_server: "b-1.cdcnbstestdevelopment.toyoo7.c10.kafka.us-east-1.amazonaws.com:9092,b-2.cdcnbstestdevelopment.toyoo7.c10.kafka.us-east-1.amazonaws.com:9092"

  sqlserverconnector_odse: {
    "name": "debezium-odse-connector-v013125",
    "config": {
      "connector.class": "io.debezium.connector.sqlserver.SqlServerConnector",
      "database.hostname": "nbs-db.private-test.nbspreview.com",
      "database.port": "1433",
      "database.user": "",
      "database.password": "",
      "database.dbname": "nbs_odse",
      "database.names": "nbs_odse",
      "database.server.name": "odse",
      "database.history.kafka.bootstrap.servers": "b-1.cdcnbstestdevelopment.toyoo7.c10.kafka.us-east-1.amazonaws.com:9092,b-2.cdcnbstestdevelopment.toyoo7.c10.kafka.us-east-1.amazonaws.com:9092",
      "database.history.kafka.topic": "dbhistory.database_server_name.database_name",
      # Uncomment following to manually bypass the sqlserver agent status query results
      #"database.sqlserver.agent.status.query": "select dbo.IsSqlAgentRunning()",
      "database.trustServerCertificate": "true",
      "include.schema.changes": "true",
      "key.converter": "org.apache.kafka.connect.json.JsonConverter",
      "key.converter.schemas.enable": "true",
      "producer.max.request.size": "10000000", #10MB
      "producer.message.max.bytes": "10000000", #10MB
      "snapshot.mode": "no_data",
      "schema.history.internal.kafka.topic": "odse-schema-history",
      "schema.history.internal.kafka.bootstrap.servers": "b-1.cdcnbstestdevelopment.toyoo7.c10.kafka.us-east-1.amazonaws.com:9092,b-2.cdcnbstestdevelopment.toyoo7.c10.kafka.us-east-1.amazonaws.com:9092",
      "table.include.list": "dbo.Person, dbo.Organization, dbo.Observation, dbo.Public_health_case, dbo.Treatment,
                             dbo.state_defined_field_data, dbo.Notification, dbo.Interview, dbo.CN_transportq_out,
                             dbo.Place, dbo.CT_contact, dbo.Auth_user, dbo.Intervention",
      "tasks.max": "1",
      "topic.prefix": "cdc",
      "topic.creation.default.replication.factor": 2,
      "topic.creation.default.partitions": 10,
      "topic.creation.default.cleanup.policy": "compact",
      "transforms": "dropPrefix, convertTimezone",
      "transforms.dropPrefix.regex": "cdc\\.NBS_ODSE\\.dbo\\.(.+)",
      "transforms.dropPrefix.type": "org.apache.kafka.connect.transforms.RegexRouter",
      "transforms.dropPrefix.replacement": "nbs_$1",
      "transforms.convertTimezone.type": "io.debezium.transforms.TimezoneConverter",
      "transforms.convertTimezone.converted.timezone": "UTC",
      "value.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter.schemas.enable": "true",
    }
  }

  sqlserverconnector_srte: {
    "name": "debezium-srte-connector-v013125",
    "config": {
      "connector.class": "io.debezium.connector.sqlserver.SqlServerConnector",
      "database.hostname": "nbs-db.private-test.nbspreview.com",
      "database.port": "1433",
      "database.user": "",
      "database.password": "",
      "database.dbname": "nbs_srte",
      "database.names": "nbs_srte",
      "database.server.name": "srte",
      "database.history.kafka.bootstrap.servers": "b-1.cdcnbstestdevelopment.toyoo7.c10.kafka.us-east-1.amazonaws.com:9092,b-2.cdcnbstestdevelopment.toyoo7.c10.kafka.us-east-1.amazonaws.com:9092",
      "database.history.kafka.topic": "dbhistory.database_server_name.database_name",
      # Uncomment following to manually bypass the sqlserver agent status query results
      #"database.sqlserver.agent.status.query": "select dbo.IsSqlAgentRunning()",
      "database.trustServerCertificate": "true",
      "include.schema.changes": "true",
      "key.converter": "org.apache.kafka.connect.json.JsonConverter",
      "key.converter.schemas.enable": "true",
      "producer.max.request.size": "10000000", #10MB
      "producer.message.max.bytes": "10000000", #10MB
      "snapshot.mode": "initial",
      "schema.history.internal.kafka.topic": "srte-schema-history",
      "schema.history.internal.kafka.bootstrap.servers": "b-1.cdcnbstestdevelopment.toyoo7.c10.kafka.us-east-1.amazonaws.com:9092,b-2.cdcnbstestdevelopment.toyoo7.c10.kafka.us-east-1.amazonaws.com:9092",
      "table.include.list": "dbo.TotalIDM,dbo.IMRDBMapping,dbo.Program_area_code,dbo.Code_value_general,dbo.Codeset,dbo.Codeset_Group_Metadata, dbo.State_county_code_value,dbo.Country_code,dbo.Jurisdiction_code,dbo.Condition_code",
      "tasks.max": "1",
      "topic.prefix": "cdc",
      "topic.creation.default.replication.factor": 2,
      "topic.creation.default.partitions": 10,
      "topic.creation.default.cleanup.policy": "compact",
      "time.precision.mode": "connect",
      "transforms": "dropPrefix, convertTimezone, unwrap, convertTimestamps_add_time, convertTimestamps_concept_status_time, convertTimestamps_effective_from_time, convertTimestamps_effective_to_time, convertTimestamps_status_time, convertTimestamps_status_to_time, convertTimestamps_value_set_status_time",
      "transforms.dropPrefix.regex": "cdc\\.NBS_SRTE\\.dbo\\.(.+)",
      "transforms.dropPrefix.type": "org.apache.kafka.connect.transforms.RegexRouter",
      "transforms.dropPrefix.replacement": "nrt_srte_$1",
      "transforms.convertTimezone.type": "io.debezium.transforms.TimezoneConverter",
      "transforms.convertTimezone.converted.timezone": "UTC",
      "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
      transforms.convertTimestamps_add_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_add_time.target.type: "string",
      transforms.convertTimestamps_add_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_add_time.field: "add_time",
      transforms.convertTimestamps_concept_status_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_concept_status_time.target.type: "string",
      transforms.convertTimestamps_concept_status_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_concept_status_time.field: "concept_status_time",
      transforms.convertTimestamps_effective_from_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_effective_from_time.target.type: "string",
      transforms.convertTimestamps_effective_from_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_effective_from_time.field: "effective_from_time",
      transforms.convertTimestamps_effective_to_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_effective_to_time.target.type: "string",
      transforms.convertTimestamps_effective_to_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_effective_to_time.field: "effective_to_time",
      transforms.convertTimestamps_status_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_status_time.target.type: "string",
      transforms.convertTimestamps_status_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_status_time.field: "status_time",
      transforms.convertTimestamps_status_to_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_status_to_time.target.type: "string",
      transforms.convertTimestamps_status_to_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_status_to_time.field: "status_to_time",
      transforms.convertTimestamps_value_set_status_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_value_set_status_time.target.type: "string",
      transforms.convertTimestamps_value_set_status_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_value_set_status_time.field: "value_set_status_time",
      "value.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter.schemas.enable": "true"
    }
  }

  env:
    - name: BOOTSTRAP_SERVERS
      value: "b-1.cdcnbstestdevelopment.toyoo7.c10.kafka.us-east-1.amazonaws.com:9092,b-2.cdcnbstestdevelopment.toyoo7.c10.kafka.us-east-1.amazonaws.com:9092"
    - name: LOG_LEVEL
      value: "INFO"
    - name: KAFKA_LOG4J_OPTS
      value: "-Dlog4j.configuration=file:/kafka/config/log4j.properties"
    - name: NAME
      value: "debezium-odse-srte-connector-v013125"
    - name: TZ
      value: "UTC"

ui:
  enabled: false
  replicaCount: 1
  imagePullSecrets: [ ]

  image:
    repository: debezium/debezium-ui
    pullPolicy: Always
    tag: "2.7"

  service:
    type: ClusterIP
    port: "8080"
    protocol: TCP
    name: http

  ingress:
    enabled: true
    router: private
    host: DEBEZIUM_UI_HOST_ADDRESS

  autoscaling:
    enabled: false

  resources:
    limits:
      cpu: 500m
      memory: 1Gi
    requests:
      cpu: 500m
      memory: 1Gi

  env:
    - name: KAFKA_CONNECT_URIS
      value: "http://debezium-connect:8083"
    - name: TZ
      value: "UTC"

