nameOverride: ""
fullnameOverride: ""
log_level: INFO # DEBUG, INFO, ERROR

connect:
  replicaCount: 1
  imagePullSecrets: [ ]

  image:
    repository: quay.io/debezium/connect
    pullPolicy: IfNotPresent
    tag: "2.7"

  service:
    type: ClusterIP
    port: 8083
    protocol: TCP
    name: http

  ingress:
    enabled: false

  autoscaling:
    enabled: false

  resources:
    limits:
      cpu: 1000m
      memory: 2Gi
    requests:
      cpu: 500m
      memory: 1Gi

  properties:
    group_id: "debezium-odse-srte-connector-v013125"
    topics_basename: "debezium-odse-srte-connector"
    default_replication_factor: 2
    default_partitions: 10
    default_cleanup: "compact"
    bootstrap_server: "wn0-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092,wn1-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092,wn2-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092"
    sql_server_agent_override: true
    sql_server_agent_status: "select dbo.IsSqlAgentRunning()"

  connector_enable:
    nbs_odse: "enabled"
    nbs_srte: "enabled"
    nbs_odse_meta: "disabled"

  sqlserverconnector_odse: {
    "name": "debezium-odse-connector-v013125",
    "config": {
      "connector.class": "io.debezium.connector.sqlserver.SqlServerConnector",
      "database.hostname": "tf-cdc-nbs6-sql-managed-instance.cdf5734b998e.database.windows.net",
      "database.port": "1433",
      "database.user": "nbs_ods",
      "database.password": "ods",
      "database.dbname": "nbs_odse",
      "database.names": "nbs_odse",
      "database.server.name": "odse",
      "database.history.kafka.bootstrap.servers": "wn0-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092,wn1-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092,wn2-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092",
      "database.history.kafka.topic": "dbhistory.database_server_name.database_name",
#      manually bypass the sqlserver agent status query
      "database.sqlserver.agent.status.query": "select dbo.IsSqlAgentRunning()",
      "database.trustServerCertificate": "true",
      "include.schema.changes": "true",
      "key.converter": "org.apache.kafka.connect.json.JsonConverter",
      "key.converter.schemas.enable": "true",
      "producer.max.request.size": "10000000", #10MB
      "producer.message.max.bytes": "10000000", #10MB
      "snapshot.mode": "no_data",
      "schema.history.internal.kafka.topic": "odse-schema-history",
      "schema.history.internal.kafka.bootstrap.servers": "wn0-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092,wn1-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092,wn2-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092",
      "table.include.list": "dbo.Person, dbo.Organization, dbo.Observation, dbo.Public_health_case, dbo.Treatment,
                                   dbo.state_defined_field_data, dbo.Notification, dbo.Interview, dbo.CN_transportq_out,
                                   dbo.Place, dbo.CT_contact, dbo.Auth_user, dbo.Intervention",
      "tasks.max": "1",
      "topic.prefix": "cdc",
      "topic.creation.default.replication.factor": 2,
      "topic.creation.default.partitions": 10,
      "topic.creation.default.cleanup.policy": "compact",
      "transforms": "dropPrefixConfig, dropPrefix, convertTimezone, unwrapConfig, convertTimestampsConfig_add_time,
                     convertTimestampsConfig_last_chg_time, convertTimestampsConfig_status_time",
      "predicates": "isConfigTable",
      "transforms.dropPrefix.regex": "cdc\\.NBS_ODSE\\.dbo\\.(.+)",
      "transforms.dropPrefix.type": "org.apache.kafka.connect.transforms.RegexRouter",
      "transforms.dropPrefix.replacement": "nbs_$1",
      "transforms.dropPrefixConfig.regex": "cdc\\.NBS_ODSE\\.dbo\\.NBS_configuration",
      "transforms.dropPrefixConfig.type": "org.apache.kafka.connect.transforms.RegexRouter",
      "transforms.dropPrefixConfig.replacement": "nrt_NBS_configuration",
      "transforms.unwrapConfig.type": "io.debezium.transforms.ExtractNewRecordState",
      "transforms.unwrapConfig.predicate": "isConfigTable",
      "transforms.convertTimestampsConfig_add_time.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      "transforms.convertTimestampsConfig_add_time.target.type": "string",
      "transforms.convertTimestampsConfig_add_time.format": "yyyy-MM-dd HH:mm:ss.SSS",
      "transforms.convertTimestampsConfig_add_time.field": "add_time",
      "transforms.convertTimestampsConfig_add_time.predicate": "isConfigTable",
      "transforms.convertTimestampsConfig_last_chg_time.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      "transforms.convertTimestampsConfig_last_chg_time.target.type": "string",
      "transforms.convertTimestampsConfig_last_chg_time.format": "yyyy-MM-dd HH:mm:ss.SSS",
      "transforms.convertTimestampsConfig_last_chg_time.field": "last_chg_time",
      "transforms.convertTimestampsConfig_last_chg_time.predicate": "isConfigTable",
      "transforms.convertTimestampsConfig_status_time.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      "transforms.convertTimestampsConfig_status_time.target.type": "string",
      "transforms.convertTimestampsConfig_status_time.format": "yyyy-MM-dd HH:mm:ss.SSS",
      "transforms.convertTimestampsConfig_status_time.field": "status_time",
      "transforms.convertTimestampsConfig_status_time.predicate": "isConfigTable",
      "predicates.isConfigTable.type": "org.apache.kafka.connect.transforms.predicates.TopicNameMatches",
      "predicates.isConfigTable.pattern": "nrt_NBS_configuration",
      "transforms.convertTimezone.type": "io.debezium.transforms.TimezoneConverter",
      "transforms.convertTimezone.converted.timezone": "UTC",
      "value.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter.schemas.enable": "true",
    }
  }
  sqlserverconnector_srte: {
    "name": "debezium-srte-connector-v013125",
    "config": {
      "connector.class": "io.debezium.connector.sqlserver.SqlServerConnector",
      "database.hostname": "tf-cdc-nbs6-sql-managed-instance.cdf5734b998e.database.windows.net",
      "database.port": "1433",
      "database.user": "nbs_ods",
      "database.password": "ods",
      "database.dbname": "nbs_srte",
      "database.names": "nbs_srte",
      "database.server.name": "srte",
      "database.history.kafka.bootstrap.servers": "wn0-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092,wn1-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092,wn2-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092",
      "database.history.kafka.topic": "dbhistory.database_server_name.database_name",
      #      manually bypass the sqlserver agent status query
      "database.sqlserver.agent.status.query": "select dbo.IsSqlAgentRunning()",
      "database.trustServerCertificate": "true",
      "include.schema.changes": "true",
      "key.converter": "org.apache.kafka.connect.json.JsonConverter",
      "key.converter.schemas.enable": "true",
      "producer.max.request.size": "10000000", #10MB
      "producer.message.max.bytes": "10000000", #10MB
      "snapshot.mode": "initial",
      "schema.history.internal.kafka.topic": "srte-schema-history",
      "schema.history.internal.kafka.bootstrap.servers": "wn0-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092,wn1-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092,wn2-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092",
      "table.include.list": "dbo.Jurisdiction_participation,dbo.Language_code,dbo.State_code,dbo.Unit_code,
                             dbo.Cntycity_code_value,dbo.Lab_result,dbo.Country_code,dbo.Labtest_loinc,dbo.ELR_XREF,
                             dbo.Loinc_condition,dbo.Loinc_snomed_condition,dbo.Lab_test,dbo.Zip_code_value,
                             dbo.Zipcnty_code_value,dbo.Lab_result_Snomed,dbo.Investigation_code,dbo.TotalIDM,
                             dbo.IMRDBMapping,dbo.Anatomic_site_code,dbo.Jurisdiction_code,dbo.Lab_coding_system,
                             dbo.City_code_value,dbo.LDF_page_set,dbo.LOINC_code,dbo.NAICS_Industry_code,
                             dbo.Codeset_Group_Metadata,dbo.Country_Code_ISO,dbo.DATABASECHANGELOGLOCK,
                             dbo.Occupation_code,dbo.Country_XREF,dbo.Standard_XREF,dbo.Code_value_clinical,
                             dbo.Code_value_general,dbo.Race_code,dbo.Participation_type,dbo.Specimen_source_code,
                             dbo.Snomed_code,dbo.State_county_code_value,dbo.State_model,dbo.Codeset,dbo.Program_area_code,
                             dbo.Labtest_Progarea_Mapping,dbo.Treatment_code,dbo.Condition_code",
      "transforms": "dropPrefix, convertTimezone, unwrap, convertTimestamps_add_time, convertTimestamps_concept_status_time, 
                     convertTimestamps_effective_from_time, convertTimestamps_effective_to_time, convertTimestamps_status_time, 
                     convertTimestamps_status_to_time, convertTimestamps_value_set_status_time",
      "transforms.dropPrefix.regex": "cdc\\.NBS_SRTE\\.dbo\\.(.+)",
      "transforms.dropPrefix.type": "org.apache.kafka.connect.transforms.RegexRouter",
      "transforms.dropPrefix.replacement": "nrt_srte_$1",
      "transforms.convertTimezone.type": "io.debezium.transforms.TimezoneConverter",
      "transforms.convertTimezone.converted.timezone": "UTC",
      "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
      transforms.convertTimestamps_add_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_add_time.target.type: "string",
      transforms.convertTimestamps_add_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_add_time.field: "add_time",
      transforms.convertTimestamps_concept_status_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_concept_status_time.target.type: "string",
      transforms.convertTimestamps_concept_status_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_concept_status_time.field: "concept_status_time",
      transforms.convertTimestamps_effective_from_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_effective_from_time.target.type: "string",
      transforms.convertTimestamps_effective_from_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_effective_from_time.field: "effective_from_time",
      transforms.convertTimestamps_effective_to_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_effective_to_time.target.type: "string",
      transforms.convertTimestamps_effective_to_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_effective_to_time.field: "effective_to_time",
      transforms.convertTimestamps_status_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_status_time.target.type: "string",
      transforms.convertTimestamps_status_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_status_time.field: "status_time",
      transforms.convertTimestamps_status_to_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_status_to_time.target.type: "string",
      transforms.convertTimestamps_status_to_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_status_to_time.field: "status_to_time",
      transforms.convertTimestamps_value_set_status_time.type: "org.apache.kafka.connect.transforms.TimestampConverter$Value",
      transforms.convertTimestamps_value_set_status_time.target.type: "string",
      transforms.convertTimestamps_value_set_status_time.format: "yyyy-MM-dd HH:mm:ss.SSS",
      transforms.convertTimestamps_value_set_status_time.field: "value_set_status_time",
      "value.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter.schemas.enable": "true"
    }
  }

  env:
    - name: BOOTSTRAP_SERVERS
      value: "wn0-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092,wn1-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092,wn2-dev-hd.dsnw3omymczu3cea2rtxoridtc.bx.internal.cloudapp.net:9092"
    - name: LOG_LEVEL
      value: "INFO"
    - name: KAFKA_LOG4J_OPTS
      value: "-Dlog4j.configuration=file:/kafka/config/log4j.properties"
    - name: NAME
      value: "debezium-odse-srte-connector-v013125"
    - name: TZ
      value: "UTC"

ui:
  enabled: false
  replicaCount: 1
  imagePullSecrets: [ ]

  image:
    repository: debezium/debezium-ui
    pullPolicy: Always
    tag: "2.7"

  service:
    type: ClusterIP
    port: "8080"
    protocol: TCP
    name: http

  ingress:
    enabled: true
    router: private
    host: DEBEZIUM_UI_HOST_ADDRESS

  autoscaling:
    enabled: false

  resources:
    limits:
      cpu: 500m
      memory: 1Gi
    requests:
      cpu: 500m
      memory: 1Gi

  env:
    - name: KAFKA_CONNECT_URIS
      value: "http://debezium-connect:8083"
    - name: TZ
      value: "UTC"

