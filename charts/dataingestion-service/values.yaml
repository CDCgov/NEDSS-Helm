replicaCount: 1

env: "prod"

image:
  #repository: "public.ecr.aws/o1z7u2g7/cdc-nbs-modernization/data-ingestion-service"
  repository: "quay.io/us-cdcgov/cdc-nbs-modernization/data-ingestion-service"
  pullPolicy: IfNotPresent
  tag: "v1.2.12"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/path: "/actuator/prometheus"
  prometheus.io/port: "8081"

podSecurityContext: {}

securityContext: {}

service:
  type: ClusterIP
  port: 8081
  httpsPort: 443

reportingService:
  enabled: "true"
  personReportingServicePort: 8091
  organizationReportingServicePort: 8092
  investigationReportingServicePort: 8093
  observationReportingServicePort: 8094
  postProcessingReportingServicePort: 8095
  ldfdataReportingServicePort: 8097

dataprocessingService:
  enabled: "true"
  port: 8082

nndService:
  enabled: "true"
  port: 8081

srtedataService:
  enabled: "true"
  port: 8084

dataExtraction:
  enabled: "true"
  port: 8090

caseNotification:
  enabled: "true"
  port: 8093 

xmlHl7Parser:
  enabled: "true"
  port: 8088

compare:
  enabled: "false"
  port: 8085

ingress:
  enabled: true
  className: "nginx"
  tls:
  - secretName: "data.EXAMPLE_DOMAIN"
    hosts:
    - "data.EXAMPLE_DOMAIN"

resources: {}

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

ingressHost: "data.EXAMPLE_DOMAIN"

# dbserver is passed in as an environment variable. It is just the database endpoint
jdbc:
  dbserver: "EXAMPLE_DB_ENDPOINT"
  username: "EXAMPLE_ODSE_DB_USER"
  password: "EXAMPLE_ODSE_DB_USER_PASSWORD"

kafka:
  cluster: "EXAMPLE_MSK_KAFKA_ENDPOINT"

log:
  path: "/usr/share/dataingestion/data"

cloudProvider: aws

#Azure PVC Settings#
azure:
  files:
    resourceGroupName: 
    storageAccountName: 
    storageClass: azurefile-csi-private-di
    storageRequest: 20Gi

#AWS PVC Settings#

pvc:
  diPvClaim:
    storageClass: efs-dataingestion
    storageRequest: 20Gi

efsFileSystemId: "EXAMPLE_EFS_ID"

#authUri: "http://keycloak.keycloak.svc.cluster.local/realms/NBS"
authUri: "http://keycloak.default.svc.cluster.local/auth/realms/NBS"

sftp:
  enabled: "EXAMPLE_SFTP_ENABLED"
  host: "EXAMPLE_SFTP_HOST"
  username: "EXAMPLE_SFTP_USER"
  password: "EXAMPLE_SFTP_PASS"
  # need to fix search and replace for both these examples <<EXAMPLE_FIXME_SFTP_SEARCH_AND_REPLACE>>
  #elrFileExtns: "EXAMPLE_SFTP_FILE_EXTNS"
  #filePaths: "EXAMPLE_SFTP_FILE_PATHS"
  elrFileExtns: "hl7,txt"
  filePaths: "/"  
# filePaths value should be comma seperated like "/,/LAB-1,/lab-2,/lab-2/lab2-sub-folder"
##################################
features:
  obrSplitting:
    enabled: false
  hl7BatchSplitting:
    enabled: false

apiPayloadMaxSize: "100MB"

# Override available for readiness and liveness probes: path, port, initialDelaySeconds, periodSeconds, failureThreshold
probes:
  readiness:
    enabled: true
  liveness:
    enabled: true

